{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the CNN\n",
    "\n",
    "In this tutorial we are going to train the CNN using the patches extracted in the previous demo ([link](patches-extraction-rgb-CC-347.ipynb)). The CNN architecture we are using is illustrated in the figure below. \n",
    "\n",
    "<img src=\"../Figures/arhcitecture_unet_mod.png\" alt=\"Drawing\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "import random\n",
    "import time\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "MY_UTILS_PATH = \"../Modules/\"\n",
    "if not MY_UTILS_PATH in sys.path:\n",
    "    sys.path.append(MY_UTILS_PATH)\n",
    "import ipt_utils\n",
    "import cnn_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(416400, 64, 64, 3)\n",
      "float32\n",
      "(416400, 64, 64, 1)\n",
      "float32\n",
      "0.170257\n"
     ]
    }
   ],
   "source": [
    "#Set this path accordingly\n",
    "patches_path = \"/Users/robertosouza/Documents/Patches-CC347\"\n",
    "\n",
    "#Listing patches (original and masks)\n",
    "orig_patches = np.array([f for f in os.listdir(patches_path) if f.endswith(\"_orig.npy\")])\n",
    "staple_patches = np.array([f.split(\"_orig\")[0] + \"_staple.npy\" for f in orig_patches])\n",
    "\n",
    "#Shuffling patches\n",
    "indexes = np.arange(orig_patches.size,dtype = int)\n",
    "np.random.shuffle(indexes)\n",
    "orig_patches = orig_patches[indexes]\n",
    "staple_patches = staple_patches[indexes]\n",
    "\n",
    "#This info comes from the part I demo\n",
    "patch_size = (64,64)\n",
    "max_value = 1000.0\n",
    "nsubjects = len(orig_patches)\n",
    "nslices = 120\n",
    "npatches = 10\n",
    "\n",
    "#Pre-allocating patches' array\n",
    "patches = np.zeros((nslices*npatches*nsubjects,patch_size[0],patch_size[1],3),dtype = np.float32)\n",
    "labels = np.zeros((nslices*npatches*nsubjects,patch_size[0],patch_size[1],1),dtype = np.float32)\n",
    "\n",
    "# Loading patches\n",
    "counter = 0\n",
    "step = nslices*npatches\n",
    "for (ii,jj) in zip(orig_patches,staple_patches):\n",
    "   aux_patches = np.load(os.path.join(patches_path,ii))\n",
    "   aux_labels = np.load(os.path.join(patches_path,jj))[:,:,:,np.newaxis]\n",
    "   patches[counter*step:(counter+1)*step] = aux_patches\n",
    "   labels[counter*step:(counter+1)*step] = aux_labels\n",
    "   counter+=1\n",
    "\n",
    "patches /= max_value\n",
    "#Patches info\n",
    "print patches.shape\n",
    "print patches.dtype\n",
    "print labels.shape\n",
    "print labels.dtype\n",
    "print patches.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "(291600, 64, 64, 3)\n",
      "Validation set\n",
      "(124800, 64, 64, 3)\n",
      "Mean, std:\n",
      "0.169724\n",
      "0.140386\n"
     ]
    }
   ],
   "source": [
    "#Percentage of the data used for validation\n",
    "val_perc = 0.3\n",
    "\n",
    "# Train and validation split     \n",
    "val = int(val_perc*nsubjects)*nslices*npatches        \n",
    "train01 = patches[:-val]\n",
    "labels01 = labels[:-val]        \n",
    "val01 = patches[-val:]\n",
    "labels_val01 = labels[-val:]\n",
    "\n",
    "#Standardization        \n",
    "mean = np.mean(train01)  \n",
    "std = np.std(train01)\n",
    "train01 -= mean\n",
    "train01 /= std\n",
    "\n",
    "val01-= mean\n",
    "val01/= std\n",
    "print \"Train set\"\n",
    "print train01.shape\n",
    "print \"Validation set\"\n",
    "print val01.shape\n",
    "print \"Mean, std:\"\n",
    "print mean\n",
    "print std\n",
    "#Saving stats\n",
    "np.save(\"../Data/ss_unet_cc347.npy\",np.array([mean,std]))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# String used to save models after each epoch\n",
    "model_name = \"../Data/ss_unet_cc_347_best.hdf5\"\n",
    "\n",
    "# Early stopping callback to shut down training after\n",
    "#10 epochs with no improvement\n",
    "earlyStopping = EarlyStopping(monitor='val_dice_coef',\n",
    "                                       patience=3, \n",
    "                                       verbose=0, mode='max')\n",
    "\n",
    "# Checkpoint callback to save model  along the epochs\n",
    "checkpoint = ModelCheckpoint(model_name, mode = 'max', \\\n",
    "                             monitor='val_dice_coef',verbose=0,\\\n",
    "                             save_best_only=False, save_weights_only = True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 291600 samples, validate on 124800 samples\n",
      "Epoch 1/100\n",
      "  1792/291600 [..............................] - ETA: 32129s - loss: -0.5429 - dice_coef: 0.5429"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "model = cnn_utils.get_unet_mod(patch_size = (64,64),\\\n",
    "                               learning_rate = 1e-4,\\\n",
    "                               learning_decay = 5e-9)\n",
    "\n",
    "hist = model.fit(train01,labels01,epochs=100,\n",
    "                 batch_size = 64,verbose=1,\n",
    "                 validation_data= (val01,labels_val01),\n",
    "                 callbacks=[checkpoint,earlyStopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving training history\n",
    "np.save(\"../Data/loss_cc347.npy\",np.array(hist.history['loss']))\n",
    "np.save(\"../Data/val_loss_cc347.npy\",np.array(hist.history['val_loss']))\n",
    "\n",
    "loss = np.array(hist.history['loss'])\n",
    "val_loss = np.array(hist.history['val_loss'])\n",
    "\n",
    "plt.figure(figsize = (4,4/1.5),facecolor = \"w\",dpi = 450)\n",
    "plt.plot(-1*loss,'x-', markersize = 4,label = \"Train\")\n",
    "plt.plot(-1*val_loss,'+-',markersize = 4,label = \"Validation\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlim(0,99)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Dice coefficient\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
